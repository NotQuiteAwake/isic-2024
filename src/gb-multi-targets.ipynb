{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/abdmental01/multimodel-isic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import io\n",
    "import warnings\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from transformers import AutoModelForImageClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "import joblib\n",
    "\n",
    "OWN_INSTANCE = True\n",
    "SEED = 42\n",
    "n_splits = 3\n",
    "\n",
    "os.makedirs('gradboost', exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns present in test but not in train: set()\n",
      "Columns present in train but not in test: {'mel_thick_mm', 'lesion_id', 'iddx_2', 'iddx_5', 'iddx_3', 'target', 'iddx_4', 'tbp_lv_dnn_lesion_confidence', 'iddx_full', 'mel_mitotic_index', 'iddx_1'}\n",
      "CPU times: user 2.52 s, sys: 318 ms, total: 2.84 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "test_metadata_file = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n",
    "train_metadata_file = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n",
    "\n",
    "if OWN_INSTANCE:\n",
    "    test_metadata_file = 'data/test-metadata.csv'\n",
    "    train_metadata_file = 'data/train-metadata.csv'\n",
    "\n",
    "test = pd.read_csv(test_metadata_file)\n",
    "train = pd.read_csv(train_metadata_file)\n",
    "\n",
    "#train.drop('isic_id',axis=1,inplace=True)\n",
    "#test.drop('isic_id',axis=1,inplace=True)\n",
    "\n",
    "test_columns = set(test.columns)\n",
    "train_columns = set(train.columns)\n",
    "\n",
    "diff_test_train = test_columns - train_columns\n",
    "diff_train_test = train_columns - test_columns\n",
    "\n",
    "if not diff_test_train and not diff_train_test:\n",
    "    print(\"Both DataFrames have the same columns.\")\n",
    "else:\n",
    "    print(\"Columns present in test but not in train:\", diff_test_train)\n",
    "    print(\"Columns present in train but not in test:\", diff_train_test)\n",
    "\n",
    "train.drop(columns=['iddx_4', 'mel_mitotic_index', 'iddx_1', 'lesion_id', 'tbp_lv_dnn_lesion_confidence',\n",
    "                    'iddx_5', 'mel_thick_mm', 'iddx_2', 'iddx_full', 'iddx_3'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.66 s, sys: 471 ms, total: 2.13 s\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def fe(df):\n",
    "    \n",
    "    # a sort of eccentricity\n",
    "    df[\"lesion_size_ratio\"]=df[\"tbp_lv_minorAxisMM\"]/df[\"clin_size_long_diam_mm\"]\n",
    "    # another dimensionless measure of eccentricity (think circle / square)\n",
    "    df[\"lesion_shape_index\"]=df[\"tbp_lv_areaMM2\"]/(df[\"tbp_lv_perimeterMM\"]**2)\n",
    "    # contrast between hue inside and outside\n",
    "    df[\"hue_contrast\"]= (df[\"tbp_lv_H\"]-df[\"tbp_lv_Hext\"]).abs()\n",
    "    # contrast between luminance inside and outside\n",
    "    df[\"luminance_contrast\"]= (df[\"tbp_lv_L\"]-df[\"tbp_lv_Lext\"]).abs()\n",
    "    # LAB is another color space similar to RGB. delta's are inside v. outside.\n",
    "    df[\"lesion_color_difference\"]=np.sqrt(df[\"tbp_lv_deltaA\"]**2+df[\"tbp_lv_deltaB\"]**2+df[\"tbp_lv_deltaL\"]**2)\n",
    "    # both metrics increase when asymmetry is higher and are on scale 0-10\n",
    "    df[\"border_complexity\"]=df[\"tbp_lv_norm_border\"]+df[\"tbp_lv_symm_2axis\"]\n",
    "    # position on 3D TBP\n",
    "    df[\"3d_position_distance\"]=np.sqrt(df[\"tbp_lv_x\"]**2+df[\"tbp_lv_y\"]**2+df[\"tbp_lv_z\"]**2)\n",
    "    # another measure of irregularity...?\n",
    "    df[\"perimeter_to_area_ratio\"]=df[\"tbp_lv_perimeterMM\"]/df[\"tbp_lv_areaMM2\"]\n",
    "    # contrast between lesion and surrounding, values from 5-25 + color variation 0 - 10\n",
    "    df[\"lesion_visibility_score\"]=df[\"tbp_lv_deltaLBnorm\"]+df[\"tbp_lv_norm_color\"]\n",
    "    # both are location indicators\n",
    "    df[\"combined_anatomical_site\"]=df[\"anatom_site_general\"]+\"_\"+df[\"tbp_lv_location\"]\n",
    "    # only when both are large does a lesion score high on this (cf border_complexity)\n",
    "    df[\"symmetry_border_consistency\"]=df[\"tbp_lv_symm_2axis\"]*df[\"tbp_lv_norm_border\"]\n",
    "    # whether the variation in color is similar inside and outside lesion\n",
    "    df[\"color_consistency\"]=df[\"tbp_lv_stdL\"]/df[\"tbp_lv_stdLExt\"]\n",
    "    # interactions are just products\n",
    "    df[\"size_age_interaction\"]=df[\"clin_size_long_diam_mm\"]*df[\"age_approx\"]\n",
    "    # hue inside and color irregularity\n",
    "    df[\"hue_color_std_interaction\"]=df[\"tbp_lv_H\"]*df[\"tbp_lv_color_std_mean\"]\n",
    "    # three measures of irregularity combined.\n",
    "    df[\"lesion_severity_index\"]=(df[\"tbp_lv_norm_border\"]+df[\"tbp_lv_norm_color\"]+df[\"tbp_lv_eccentricity\"])/3\n",
    "    df[\"shape_complexity_index\"]=df[\"border_complexity\"]+df[\"lesion_shape_index\"]\n",
    "    # first three terms are average contrast, last term is contrast in immediately surrounding skin\n",
    "    df[\"color_contrast_index\"]=df[\"tbp_lv_deltaA\"]+df[\"tbp_lv_deltaB\"]+df[\"tbp_lv_deltaL\"]+df[\"tbp_lv_deltaLBnorm\"]\n",
    "    # the malignant lesions can be way longer and a log scale might better capture this\n",
    "    df[\"log_lesion_area\"]=np.log(df[\"tbp_lv_areaMM2\"]+1)\n",
    "    # perhaps lesion gorws in size with age.\n",
    "    df[\"normalized_lesion_size\"]=df[\"clin_size_long_diam_mm\"]/df[\"age_approx\"]\n",
    "    # internal and external hue averaged\n",
    "    df[\"mean_hue_difference\"]=(df[\"tbp_lv_H\"]+df[\"tbp_lv_Hext\"])/2\n",
    "    # combining inner contrast assuming Gaussisna\n",
    "    df[\"std_dev_contrast\"]=np.sqrt((df[\"tbp_lv_deltaA\"]**2+df[\"tbp_lv_deltaB\"]**2+df[\"tbp_lv_deltaL\"]**2)/3)\n",
    "    # combine metrics of color and shape, both could be more irregular for malignant\n",
    "    df[\"color_shape_composite_index\"]=(df[\"tbp_lv_color_std_mean\"]+df[\"tbp_lv_area_perim_ratio\"]+df[\"tbp_lv_symm_2axis\"])/3\n",
    "    df[\"3d_lesion_orientation\"]=np.arctan2(df[\"tbp_lv_y\"],df[\"tbp_lv_x\"])\n",
    "    df[\"overall_color_difference\"]=(df[\"tbp_lv_deltaA\"]+df[\"tbp_lv_deltaB\"]+df[\"tbp_lv_deltaL\"])/3\n",
    "    df[\"symmetry_perimeter_interaction\"]=df[\"tbp_lv_symm_2axis\"]*df[\"tbp_lv_perimeterMM\"]\n",
    "    # the larger this value, the larger the \"irregularity\"\n",
    "    df[\"comprehensive_lesion_index\"]=(df[\"tbp_lv_area_perim_ratio\"]+df[\"tbp_lv_eccentricity\"]+df[\"tbp_lv_norm_color\"]+df[\"tbp_lv_symm_2axis\"])/4\n",
    "    \n",
    "    # categorical columns\n",
    "    n_cat = [\"combined_anatomical_site\"]\n",
    "    \n",
    "    return df, n_cat\n",
    "\n",
    "train, n_cat = fe(train)\n",
    "test, _ = fe(test)\n",
    "\n",
    "# columns with categories\n",
    "cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\",'patient_id',\n",
    "   'anatom_site_general','copyright_license','attribution','image_type'] + n_cat\n",
    "\n",
    "# drop columns only present in one set\n",
    "def align_columns(train, test):\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    return train, test\n",
    "\n",
    "# target will be removed by align_columns anyway, remove first and add back later.\n",
    "target = train['target']\n",
    "train_features = train.drop(columns=['target'], errors='ignore')\n",
    "\n",
    "train_features_aligned, test_features_aligned = align_columns(train_features, test)\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=cat_cols, handle_unknown='ignore')\n",
    "train = encoder.fit_transform(train_features_aligned)\n",
    "# a second call to encoder.transform will apply the same statistics of fit_transform.\n",
    "test = encoder.transform(test_features_aligned)\n",
    "\n",
    "train.drop(columns=['isic_id'], inplace = True)\n",
    "test.drop(columns=['isic_id'], inplace = True)\n",
    "\n",
    "train['target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ViT and extract feature from last hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation for image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401059/401059 [00:54<00:00, 7413.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2900.26 MiB, increment: 1360.78 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 340.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 s, sys: 3.94 s, total: 56 s\n",
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_path = '/kaggle/input/vit/transformers/default/1/'\n",
    "hdf_test_path = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
    "hdf_train_path = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\n",
    "\n",
    "if OWN_INSTANCE:\n",
    "    model_path = 'TobanDjan/vit'\n",
    "    hdf_test_path = 'data/test-image.hdf5'\n",
    "    hdf_train_path = 'data/train-image.hdf5'\n",
    "\n",
    "# Function to load images from encoded data\n",
    "def load_image_from_encoded_data(encoded_data):\n",
    "    image = Image.open(io.BytesIO(encoded_data))\n",
    "    return image.convert('RGB')\n",
    "\n",
    "# Define a custom Dataset for the HDF5 images\n",
    "class HDF5TestDataset(Dataset):\n",
    "    def __init__(self, image_data, ids, transform=None):\n",
    "        self.image_data = image_data\n",
    "        self.ids = ids\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_data = self.image_data[idx]\n",
    "        image = load_image_from_encoded_data(image_data)\n",
    "        #imshow(image)\n",
    "        #plt.show()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # print(image.element_size() * image.nelement())\n",
    "        # 602112 B = 0.574 MB\n",
    "        return image, self.ids[idx]\n",
    "\n",
    "def get_dataset(hdf_file_path):\n",
    "    with h5py.File(hdf_file_path, 'r') as f:\n",
    "        image_data = [f[image_id][()] for image_id in tqdm(f.keys())]\n",
    "        ids = list(f.keys())\n",
    "        dataset = HDF5TestDataset(image_data=image_data, ids=ids, transform=val_transform)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "%memit train_dataset = get_dataset(hdf_train_path)\n",
    "test_dataset = get_dataset(hdf_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1567/1567 [18:21<00:00,  1.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1567/1567 [23:08<00:00,  1.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1567/1567 [1:10:06<00:00,  2.68s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1567/1567 [21:27<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patient_id  age_approx  sex  anatom_site_general  clin_size_long_diam_mm  \\\n",
      "0         NaN        45.0    1                    3                    2.70   \n",
      "1         NaN        35.0    2                    1                    2.52   \n",
      "2         NaN        65.0    1                    3                    3.16   \n",
      "\n",
      "   image_type  tbp_tile_type  tbp_lv_A  tbp_lv_Aext  tbp_lv_B  tbp_lv_Bext  \\\n",
      "0           1              2  22.80433    20.007270  28.38412    27.043640   \n",
      "1           1              2  16.64867     9.657964  31.31752    27.524318   \n",
      "2           1              2  24.25384    19.937380  30.46368    28.384240   \n",
      "\n",
      "    tbp_lv_C  tbp_lv_Cext   tbp_lv_H  tbp_lv_Hext  tbp_lv_L  tbp_lv_Lext  \\\n",
      "0  36.410100    33.640000  51.220960    53.505430  24.97985    31.114600   \n",
      "1  35.467806    29.169579  62.004494    70.664619  59.90409    68.141071   \n",
      "2  38.939500    34.686660  51.474730    54.915410  35.81945    41.358640   \n",
      "\n",
      "   tbp_lv_areaMM2  tbp_lv_area_perim_ratio  tbp_lv_color_std_mean  \\\n",
      "0        3.846876                22.907010               0.461149   \n",
      "1        2.120473                18.957821               0.000000   \n",
      "2        3.396510                19.464400               0.251236   \n",
      "\n",
      "   tbp_lv_deltaA  tbp_lv_deltaB  tbp_lv_deltaL  tbp_lv_deltaLB  \\\n",
      "0       2.797056       1.340481      -6.134747        6.436557   \n",
      "1       6.990705       3.793202      -8.236981        9.151127   \n",
      "2       4.316465       2.079433      -5.539191        6.041092   \n",
      "\n",
      "   tbp_lv_deltaLBnorm  tbp_lv_eccentricity  tbp_lv_location  \\\n",
      "0            6.843057             0.664465                3   \n",
      "1            6.083388             0.926698                6   \n",
      "2            5.446997             0.894776                3   \n",
      "\n",
      "   tbp_lv_location_simple  tbp_lv_minorAxisMM  tbp_lv_nevi_confidence  \\\n",
      "0                       3            2.187644            1.698104e-02   \n",
      "1                       6            1.032666            2.107364e-01   \n",
      "2                       3            1.520786            8.052259e-13   \n",
      "\n",
      "   tbp_lv_norm_border  tbp_lv_norm_color  tbp_lv_perimeterMM  \\\n",
      "0            5.435366           1.143374            9.387248   \n",
      "1            4.322201           0.000000            6.340311   \n",
      "2            3.968912           0.721739            8.130868   \n",
      "\n",
      "   tbp_lv_radial_color_std_max  tbp_lv_stdL  tbp_lv_stdLExt  \\\n",
      "0                     0.304827     1.281532        2.299935   \n",
      "1                     0.000000     1.271940        2.011223   \n",
      "2                     0.230742     1.080308        2.705857   \n",
      "\n",
      "   tbp_lv_symm_2axis  tbp_lv_symm_2axis_angle   tbp_lv_x     tbp_lv_y  \\\n",
      "0           0.479339                       20 -155.06510  1511.222000   \n",
      "1           0.426230                       25 -112.36924   629.535889   \n",
      "2           0.366071                      110  -84.29282  1303.978000   \n",
      "\n",
      "     tbp_lv_z  attribution  copyright_license  lesion_size_ratio  \\\n",
      "0  113.980100          1.0                  1           0.810239   \n",
      "1  -15.019287          5.0                  1           0.409788   \n",
      "2  -28.576050          NaN                  1           0.481261   \n",
      "\n",
      "   lesion_shape_index  hue_contrast  luminance_contrast  \\\n",
      "0            0.043655      2.284470            6.134750   \n",
      "1            0.052749      8.660125            8.236981   \n",
      "2            0.051376      3.440680            5.539190   \n",
      "\n",
      "   lesion_color_difference  border_complexity  3d_position_distance  \\\n",
      "0                 6.874266           5.914705           1523.426592   \n",
      "1                11.450162           4.748430            639.662302   \n",
      "2                 7.323834           4.334983           1307.012048   \n",
      "\n",
      "   perimeter_to_area_ratio  lesion_visibility_score  combined_anatomical_site  \\\n",
      "0                 2.440226                 7.986431                         3   \n",
      "1                 2.990046                 6.083388                         6   \n",
      "2                 2.393889                 6.168736                         3   \n",
      "\n",
      "   symmetry_border_consistency  color_consistency  size_age_interaction  \\\n",
      "0                     2.605382           0.557204                 121.5   \n",
      "1                     1.842249           0.632421                  88.2   \n",
      "2                     1.452905           0.399248                 205.4   \n",
      "\n",
      "   hue_color_std_interaction  lesion_severity_index  shape_complexity_index  \\\n",
      "0                  23.620479               2.414402                5.958360   \n",
      "1                   0.000000               1.749633                4.801179   \n",
      "2                  12.932295               1.861809                4.386359   \n",
      "\n",
      "   color_contrast_index  log_lesion_area  normalized_lesion_size  \\\n",
      "0              4.845847         1.578334                0.060000   \n",
      "1              8.630314         1.137985                0.072000   \n",
      "2              6.303704         1.480811                0.048615   \n",
      "\n",
      "   mean_hue_difference  std_dev_contrast  color_shape_composite_index  \\\n",
      "0            52.363195          3.968859                     7.949166   \n",
      "1            66.334557          6.610754                     6.461350   \n",
      "2            53.195070          4.228418                     6.693902   \n",
      "\n",
      "   3d_lesion_orientation  overall_color_difference  \\\n",
      "0               1.673048                 -0.665737   \n",
      "1               1.747431                  0.848975   \n",
      "2               1.635349                  0.285569   \n",
      "\n",
      "   symmetry_perimeter_interaction  comprehensive_lesion_index  effnet_target  \\\n",
      "0                        4.499672                    6.298547   2.971582e-04   \n",
      "1                        2.702428                    5.077687   1.815113e-07   \n",
      "2                        2.976478                    5.361747   2.112678e-04   \n",
      "\n",
      "   beit_target  vitmae_target  vit_target  \n",
      "0     0.000432       0.001821    0.005243  \n",
      "1     0.000657       0.000295    0.003440  \n",
      "2     0.000158       0.000529    0.003024  \n"
     ]
    }
   ],
   "source": [
    "# Create the test dataset and dataloader\n",
    "batch_size = 2 ** 9\n",
    "\n",
    "if OWN_INSTANCE:\n",
    "    batch_size = 2 ** 8\n",
    "\n",
    "model = None\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def predict(model_path, dataset):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "\n",
    "    isic_ids = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, batch_ids in tqdm(dataloader, total = len(dataloader)):\n",
    "            inputs = inputs.to(device)\n",
    "            # print(inputs.element_size() * inputs.nelement())\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.logits.cpu()\n",
    "\n",
    "            outputs = softmax(outputs, axis=1)[:, 1]\n",
    "\n",
    "            isic_ids.extend(batch_ids)\n",
    "            targets.extend(outputs)\n",
    "            \n",
    "    return isic_ids, targets\n",
    "\n",
    "model_paths = [ \n",
    "    '/kaggle/input/efficientnet-b7-full/transformers/default/3/',\n",
    "    '/kaggle/input/beit/transformers/default/1',\n",
    "    '/kaggle/input/vitmae-sup/transformers/default/1',\n",
    "    '/kaggle/input/vit/transformers/default/1'\n",
    "]\n",
    "\n",
    "if OWN_INSTANCE:\n",
    "    model_paths = [\n",
    "        'TobanDjan/efficientnet-b7-2024',\n",
    "        'TobanDjan/beit',\n",
    "        'TobanDjan/vitmae-sup',\n",
    "        'TobanDjan/vit'\n",
    "    ]\n",
    "\n",
    "model_names = ['effnet', 'beit', 'vitmae', 'vit']\n",
    "\n",
    "for model_name, model_path in zip(model_names, model_paths):\n",
    "    test_isic_ids, test_targets = predict(model_path, test_dataset)\n",
    "    test[model_name + '_target']  = test_targets\n",
    "\n",
    "    train_isic_ids, train_targets = predict(model_path, train_dataset)\n",
    "    train[model_name + '_target'] = train_targets\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('target',axis=1)\n",
    "y = train['target']\n",
    "\n",
    "def pauc_above_tpr(solution, submission, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(solution)-1)\n",
    "    v_pred = np.array([1.0 - x for x in submission])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "\n",
    "def Train_ML(model_factory, X, y, test_data):\n",
    "    # k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    test_predictions = [] \n",
    "    models = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(tqdm(skf.split(X, y), total=n_splits), 1):\n",
    "        # StratifiedKFold yields the indices from which we retrieve pandas metadata\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "        \n",
    "        model = model_factory()\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # record performance on all sets\n",
    "        y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "        train_pauc = pauc_above_tpr(y_train,y_train_pred_proba, min_tpr=0.8)\n",
    "        train_scores.append(train_pauc)\n",
    "\n",
    "        y_val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "        val_pauc = pauc_above_tpr(y_val, y_val_pred_proba, min_tpr=0.8)\n",
    "        val_scores.append(val_pauc)\n",
    "        \n",
    "        # make predictions\n",
    "        y_test_pred_proba = model.predict_proba(test)[:, 1]\n",
    "        test_predictions.append(y_test_pred_proba)\n",
    "        \n",
    "        models.append(model)\n",
    "\n",
    "        print(f\"Fold {fold}: Train pAUC = {train_pauc:.4f}, Validation pAUC = {val_pauc:.4f}\")\n",
    "\n",
    "    # mean pauc on different folds' models\n",
    "    mean_train_pauc = np.mean(train_scores)\n",
    "    mean_val_pauc = np.mean(val_scores)\n",
    "\n",
    "    print(f\"\\nMean Train pAUC: {mean_train_pauc:.4f}\")\n",
    "    print(f\"Mean Validation pAUC: {mean_val_pauc:.4f}\")\n",
    "\n",
    "    # why would you want the \"model\"?\n",
    "    return model,test_predictions, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████▋                                                                                 | 1/3 [00:26<00:53, 26.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train pAUC = 0.1990, Validation pAUC = 0.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████▎                                        | 2/3 [00:51<00:25, 25.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Train pAUC = 0.1990, Validation pAUC = 0.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:16<00:00, 25.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Train pAUC = 0.1990, Validation pAUC = 0.1898\n",
      "\n",
      "Mean Train pAUC: 0.1990\n",
      "Mean Validation pAUC: 0.1887\n",
      "CPU times: user 19min 1s, sys: 1.58 s, total: 19min 3s\n",
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def lgbm_factory():\n",
    "    params =  {\n",
    "            'objective': 'binary', 'colsample_bytree': 0.6852015051268027, 'max_depth': 4, \n",
    "            'learning_rate': 0.05714390301637632, 'n_estimators': 1010, 'subsample': 0.13326633837138008, \n",
    "            'lambda_l1': 1.4445754309498806e-08, 'lambda_l2': 0.11031259304642657, 'boosting_type': 'dart'\n",
    "                }\n",
    "    \n",
    "    Model = LGBMClassifier(**params,verbose=-1,random_state=SEED,\n",
    "                          extra_tree=True,max_bin=250,reg_alpha=0.1,reg_lambda=0.8\n",
    "                          )\n",
    "    return Model\n",
    "\n",
    "train_lgb, test_preds, all_models = Train_ML(lgbm_factory, X, y, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████▋                                                                                 | 1/3 [00:42<01:24, 42.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train pAUC = 0.1986, Validation pAUC = 0.1932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████▎                                        | 2/3 [01:24<00:42, 42.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Train pAUC = 0.1994, Validation pAUC = 0.1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:07<00:00, 42.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Train pAUC = 0.1991, Validation pAUC = 0.1904\n",
      "\n",
      "Mean Train pAUC: 0.1990\n",
      "Mean Validation pAUC: 0.1897\n",
      "peak memory: 4563.01 MiB, increment: 457.35 MiB\n",
      "CPU times: user 14min 17s, sys: 2min 3s, total: 16min 21s\n",
      "Wall time: 2min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def cat_factory():\n",
    "    Cat_Model = CatBoostClassifier(verbose=0,random_state=SEED,\n",
    "                              iterations = 1000,\n",
    "                              learning_rate=0.01,\n",
    "                              objective = 'Logloss',\n",
    "                              boosting_type = 'Plain',\n",
    "                              bootstrap_type = 'Bernoulli',\n",
    "                              colsample_bylevel = 0.08656159895289164,\n",
    "                              subsample = 0.46623542352578917,\n",
    "                              depth=9,)\n",
    "    return Cat_Model\n",
    "\n",
    "%memit train_cat, cat_test_preds , Cat_all_models = Train_ML(cat_factory, X, y, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████▋                                                                                 | 1/3 [00:14<00:28, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train pAUC = 0.1987, Validation pAUC = 0.1939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████▎                                        | 2/3 [00:28<00:14, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Train pAUC = 0.1990, Validation pAUC = 0.1871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:42<00:00, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Train pAUC = 0.1987, Validation pAUC = 0.1890\n",
      "\n",
      "Mean Train pAUC: 0.1988\n",
      "Mean Validation pAUC: 0.1900\n",
      "peak memory: 4766.06 MiB, increment: 317.96 MiB\n",
      "CPU times: user 9min 32s, sys: 2.25 s, total: 9min 34s\n",
      "Wall time: 42.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def xgb_factory():\n",
    "    xgb_params2 = {\n",
    "        'objective': 'binary:logistic', 'colsample_bytree': 0.11756728710020253,'max_depth': 4, \n",
    "        'learning_rate': 0.009393224320850784,'n_estimators': 1227, 'subsample': 0.9589462514195692,\n",
    "        'lambda': 0.34216652262461505,'alpha': 1.150597512455824e-07\n",
    "                  }\n",
    "    \n",
    "    xgb_Model = XGBClassifier(**xgb_params2,random_state=SEED)\n",
    "    return xgb_Model\n",
    "\n",
    "%memit train_xgb, xgb_test_preds , xgb_all_models = Train_ML(xgb_factory, X, y, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 6.34 ms, total: 6.34 ms\n",
      "Wall time: 4.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0015657  0.000042\n",
       "1  ISIC_0015729  0.000019\n",
       "2  ISIC_0015740  0.000033"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample_file = '/kaggle/input/isic-2024-challenge/sample_submission.csv'\n",
    "\n",
    "if OWN_INSTANCE:\n",
    "    sample_file = 'data/sample_submission.csv'\n",
    "    \n",
    "Sample = pd.read_csv(sample_file)\n",
    "\n",
    "lgb_test = np.mean(test_preds, axis=0)\n",
    "cat_test = np.mean(cat_test_preds, axis=0)\n",
    "xgb_test = np.mean(xgb_test_preds, axis=0)\n",
    "\n",
    "\n",
    "ensemble_preds = (lgb_test + cat_test + xgb_test) / 3\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    'isic_id': Sample['isic_id'],\n",
    "    'target': ensemble_preds\n",
    "})\n",
    "\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_models(framework, models):\n",
    "    for idx, model in enumerate(models):\n",
    "        joblib.dump(model, f'gradboost/{framework}_{idx}.joblib')\n",
    "\n",
    "dump_models(\"lgbm\", all_models)\n",
    "dump_models(\"catboost\", Cat_all_models)\n",
    "dump_models(\"xgb\", xgb_all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 112702,
     "modelInstanceId": 88477,
     "sourceId": 105577,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
